{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grad-cam",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgEmmOyF290u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDolo9dh9dj3"
      },
      "source": [
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgJ1hhN4s9Po"
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLauIgiLQ3HT"
      },
      "source": [
        "!git clone https://github.com/kastnerkyle/deform-conv.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6crzi46HRf_Z"
      },
      "source": [
        "f = open(\"/content/deform-conv/deform_conv/layers.py\",\"wb\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "102JH5vpRo3B"
      },
      "source": [
        "f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhi3YDUPRHKc"
      },
      "source": [
        "from f import ConvOffset2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPk-EpDWazGO"
      },
      "source": [
        "normal_dir = \"/content/covid-chestxray-dataset/images\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "covid_files = glob.glob(dir)\n",
        "covid_files2 = glob.glob(dir2)\n",
        "covid_files1 = glob.glob(dir1)\n",
        "covid_files.extend(covid_files2)\n",
        "covid_files.extend(covid_files1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYEpEEa14ogH"
      },
      "source": [
        "covid_files[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXVslHcU2ije"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for i in range(len(covid_files)):\n",
        "  img = cv2.imread(covid_files[i])\n",
        "  img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "  img = img.astype('float32')/255.0\n",
        "  im = np.asarray(img)\n",
        "  \n",
        "  plt.imshow(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeQWP2gjOW4e"
      },
      "source": [
        "len(covid_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH3TjvOEFqai"
      },
      "source": [
        " ! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHI1HF4ZYsOa"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJAL8wRSYsYj"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcnY_UV-YsV_"
      },
      "source": [
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1jeN-BwWHdN"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPwxAh21ZDyl"
      },
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkjMkGelazTi"
      },
      "source": [
        "normal_dir = \"/content/chest_xray/chest_xray/train/NORMAL\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "normal_files = glob.glob(dir)\n",
        "normal_1 = glob.glob(dir1)\n",
        "normal_2 = glob.glob(dir2)\n",
        "normal_files.extend(normal_1)\n",
        "normal_files.extend(normal_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvBgm6nCOW7R"
      },
      "source": [
        "len(normal_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C26VeXYOOW-F"
      },
      "source": [
        "normal_dir = \"/content/chest_xray/chest_xray/train/PNEUMONIA\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "pneumonia_files = glob.glob(dir)\n",
        "pneumonia_1 = glob.glob(dir1)\n",
        "pneumonia_2 = glob.glob(dir2)\n",
        "pneumonia_files.extend(pneumonia_1)\n",
        "pneumonia_files.extend(pneumonia_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOzLSdGOXBJ"
      },
      "source": [
        "len(pneumonia_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8LX8xAnyH9G"
      },
      "source": [
        "train_dic = {}\n",
        "for f in covid_files[:739]:\n",
        "  train_dic[f] = [1,0,0]\n",
        "for f in normal_files[:1072]:\n",
        "  train_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[:3100]:\n",
        "  train_dic[f] = [0,0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CknqnFqh7pIl"
      },
      "source": [
        "len(pneumonia_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PnnWfEw0CS5"
      },
      "source": [
        "test_dic = {}\n",
        "for f in covid_files[739:]:\n",
        "  test_dic[f] = [1,0,0]\n",
        "for f in normal_files[1072:]:\n",
        "  test_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[3100:]:\n",
        "  test_dic[f] = [0,0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MeSq8r1hHtA"
      },
      "source": [
        "dic = list(test_dic.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9PFlfbhqGbb"
      },
      "source": [
        "import random\n",
        "l = list(train_dic.items())\n",
        "random.shuffle(l)\n",
        "l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXlpWDX02ld"
      },
      "source": [
        "\n",
        "import random\n",
        "l_test = list(test_dic.items())\n",
        "random.shuffle(l_test)\n",
        "l_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUoEi50_OXHJ"
      },
      "source": [
        "print(len(l),len(l_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx44DxJIumtd"
      },
      "source": [
        "train_features = []\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l)):\n",
        "  file_name,label = l[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    height, width = img.shape[:2]\n",
        "    #for i in range(1,5):\n",
        "      #rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2),15*i, 1)\n",
        "      #image_rotated = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "\n",
        "  except:\n",
        "    print(i,file_name)\n",
        "    print(\"Not possible\")  \n",
        "  \n",
        "       \n",
        "train_data = np.array(data)\n",
        "print(train_data.shape)\n",
        "\n",
        "train_labels = np.array(labels)\n",
        "print(train_labels.shape)    \n",
        "#data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "#discard_n = len(data)-len(data)//batch_size*batch_size;\n",
        "#data = np.delete(data,range(discard_n),axis = 0)\n",
        "print('^_^-training data finished-^_^')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Xam5Kt7y9d"
      },
      "source": [
        "test_features = []\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_test)):\n",
        "  file_name,label = l_test[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    fd,hog_img = hog(img,orientations=8,pixels_per_cell=(16,16),cells_per_block=(1,1),visualize=True,multichannel=True)\n",
        "    feature = hog_img.astype('float32')/255.0   \n",
        "    img = img.astype('float32')/255.0\n",
        "    test_features.append(feature)\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(file_name,i)  \n",
        " \n",
        "  \n",
        "test_data = np.array(data)\n",
        "print(test_data.shape)\n",
        "\n",
        "test_labels = np.array(labels)\n",
        "print(test_labels.shape)    \n",
        "#data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "#discard_n = len(data)-len(data)//batch_size*batch_size;\n",
        "#data = np.delete(data,range(discard_n),axis = 0)\n",
        "print('^_^-testing data finished-^_^')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhoYU_bkr4tq"
      },
      "source": [
        "\n",
        "inception_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet',classes = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6UTvGRKdPP6"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "#  inputs_1 = tf.expand_dims(inputs,axis = 1)\n",
        "#  lstm = tf.keras.layers.ConvLSTM2D(filters = 256,kernel_size = (3,3))(inputs_1)\n",
        "x = inception_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "#x_add = Add()([x1,x3])\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "\n",
        "\n",
        "\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "#dense_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "#dense_2 = Dropout(0.5)(dense_2)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "\n",
        "inception_pred = Model(inputs = inputs,outputs = prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUNm6l80Upt8"
      },
      "source": [
        "inception_pred.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM65t20Ye0mi"
      },
      "source": [
        "inception_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLmseq8YqELB"
      },
      "source": [
        "inception_pred.fit(train_data,train_labels,batch_size = 32,epochs = 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMUBmNCwQXrB"
      },
      "source": [
        "inception_pred.save(\"mobilenet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAEcvsMS2l-N"
      },
      "source": [
        "inception_pred = tf.keras.models.load_model(\"VGG19.h5\",compile = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS33NNkJCPb3"
      },
      "source": [
        "inception_pred.evaluate(test_data,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72ccWFGLkkma"
      },
      "source": [
        "x = inception_pred.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU6YTGHCku0_"
      },
      "source": [
        "x_pred = np.argmax(x, axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddTqTzG-k8OP"
      },
      "source": [
        "for f in range(len(test_labels)):\n",
        "  print(f,test_labels[f])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXGVRU8hk2p3"
      },
      "source": [
        "x_pred[29]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiuQEnuo7t0A"
      },
      "source": [
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq5rjdNM5c6u"
      },
      "source": [
        "\n",
        "img_size = (224, 224)\n",
        "last_conv_layer_name = \"vgg19\"\n",
        "classifier_layer_names = [\n",
        "    \"tf_op_layer_ExpandDims\",\n",
        "    \"conv_lst_m2d\",\n",
        "    \"batch_normalization\",\n",
        "    \"activation\",\n",
        "    \"global_average_pooling2d\",\n",
        "    \"dense\",\n",
        "    \"dense_1\",\n",
        "    \"multiply\",\n",
        "    \"flatten\",                      \n",
        "    \"dense_2\",                     \n",
        "    \"dense_3\",\n",
        "    \"dense_4\",\n",
        "]\n",
        "\n",
        "# The local path to our target image\n",
        "plt.imshow(test_data[1137])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QO-ly1UyymV"
      },
      "source": [
        "240"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFHe1_cmG6X"
      },
      "source": [
        "test_labels[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhhna2__xSNU"
      },
      "source": [
        "x_pred[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HzXk9hiYczW"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klV1mBmj5c4f"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Display\n",
        "\n",
        "\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZAGYnr7bKDO"
      },
      "source": [
        "classifier_input = keras.Input(shape=inception_model.output.shape[1:])\n",
        "x = classifier_input\n",
        "\n",
        "for layer_name in classifier_layer_names:\n",
        "  print(layer_name)\n",
        "  if layer_name == \"activation\":\n",
        "    x = inception_pred.get_layer(layer_name)(x)\n",
        "    k = x\n",
        "  elif layer_name == \"multiply\":\n",
        "    x = inception_pred.get_layer(layer_name)([x,k])\n",
        "  else:  \n",
        "    x = inception_pred.get_layer(layer_name)(x)\n",
        "classifier_model = keras.Model(classifier_input, x)  \n",
        "img_array = test_data[1117]\n",
        "with tf.GradientTape() as tape:\n",
        "  img = np.expand_dims(img_array,axis = 0)\n",
        "  last_conv_layer_output = inception_model(img)\n",
        "  tape.watch(last_conv_layer_output)\n",
        "  preds = classifier_model(last_conv_layer_output)\n",
        "  top_pred_index = tf.argmax(preds[0])\n",
        "  top_class_channel = preds[:, top_pred_index]\n",
        "grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "pooled_grads = pooled_grads.numpy()  \n",
        "for i in range(pooled_grads.shape[-1]):\n",
        "  last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "\n",
        "plt.imshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Lv1FuxmBW4"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2GGtpIZq4Kx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-E0TID6mFdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVnsGYX9Stc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CoClhGmngvq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBy6Hkz81pl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix_knVLBpmeD"
      },
      "source": [
        "\n",
        "img = keras.preprocessing.image.img_to_array(img_array)\n",
        "\n",
        "# We rescale heatmap to a range 0-255\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "# We use jet colormap to colorize heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "# We use RGB values of the colormap\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "# We create an image with RGB colorized heatmap\n",
        "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose the heatmap on original image\n",
        "superimposed_img = jet_heatmap * 0.0015 + img\n",
        "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-V2-EXr1Zi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7PdmYaW1Zpg"
      },
      "source": [
        "plt.imshow(test_data[980])\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "fig1.savefig('mobilenet_covid_normal.png', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn67ADXDpmjs"
      },
      "source": [
        "plt.imshow(superimposed_img)\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "fig1.savefig('mobilenet_covid_grad.png', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnSNTrLrDBn"
      },
      "source": [
        "plt.savefig(\"grad_cam_xray.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv2hjtJarDNg"
      },
      "source": [
        "test_labels[224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIUz-ZFtrDK6"
      },
      "source": [
        "x_pred[224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8iwWudmrDHT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48NlasK2rDE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGL8naKSrC-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVnSml_fpmok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enWK0SJ7pmhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrJ5Cis7Q38p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLHk-PD9RxYk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}